{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ubuntu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import Request, urlopen\n",
    "import datetime\n",
    "import string\n",
    "from string import digits\n",
    "import collections\n",
    "import scipy.stats as scs\n",
    "import cc_pipeline as P\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "#sentiment and language\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import spacy\n",
    "import vaderSentiment\n",
    "from langdetect import detect\n",
    "from gensim.models import Word2Vec\n",
    "from gensim import corpora\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import chi2\n",
    "import knee_locator\n",
    "\n",
    "#plotting\n",
    "from bokeh.plotting import figure, show, output_file, output_notebook, ColumnDataSource\n",
    "from bokeh.models import HoverTool, BoxSelectTool\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from PIL import Image\n",
    "import pyLDAvis.sklearn\n",
    "import pyLDAvis.gensim as gensimvis\n",
    "import pyLDAvis\n",
    "\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scrape_text(series):\n",
    "    \n",
    "    #use pd.series instead moving forward\n",
    "    text = []\n",
    "    for link in series:\n",
    "        \n",
    "        try:\n",
    "            req = Request(link, headers={'User-Agent': 'Mozilla/5.0'})\n",
    "            webpage = urlopen(req).read()\n",
    "            webpage = webpage.decode('utf-8')\n",
    "            text.append(webpage)\n",
    "        except SocketError as e:\n",
    "            if e.errno != errno.ECONNRESET:\n",
    "                raise # Not error we are looking for\n",
    "            pass # Handle error here.\n",
    "        \n",
    "    return text\n",
    "\n",
    "def scrape_from_url(cycles):\n",
    "    \n",
    "    for i in range(cycles):\n",
    "        \n",
    "        time.sleep(900)\n",
    "        \n",
    "        from_df = pd.read_csv('data/cc_recent.csv', encoding='utf-8')\n",
    "        temp_df = from_df.head(1000)\n",
    "\n",
    "        #scrape text then concat\n",
    "        text_url_series = pd.Series(temp_df['url'])\n",
    "        extracts = scrape_text(text_url_series)\n",
    "        extracts = pd.Series(extracts)\n",
    "        temp_df['text'] = extracts\n",
    "\n",
    "        head_df = pd.read_csv('data/cc_head_text.csv', encoding='utf-8')\n",
    "        head_df = pd.concat([head_df, temp_df])\n",
    "        head_df.to_csv('data/cc_head_text.csv', encoding='utf-8', index=False)\n",
    "\n",
    "        from_df = from_df.drop(from_df.index[0:1000])\n",
    "        from_df.to_csv('data/cc_recent.csv', encoding='utf-8', index=False)\n",
    "\n",
    "        head_df=None\n",
    "        temp_df=None\n",
    "        from_df=None\n",
    "        text_url_series=None\n",
    "        extracts=None\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape_from_url(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean text\n",
    "\n",
    "def get_show_text(show_raw):\n",
    "    \n",
    "    '''returns show text without timestamps'''\n",
    "    \n",
    "    return \"\\n\".join( [\"\\n\".join( x.split(\"\\n\")[2:] ) for x in show_raw.split(\"\\n\\n\")] )\n",
    "\n",
    "\n",
    "\n",
    "def clean_all_text(text_list):\n",
    "    \n",
    "    '''cleans all text and creates new column in dataframe'''\n",
    "    \n",
    "    doc_list = []\n",
    "    for word in text_list:\n",
    "        doc_list.append(get_show_text(word))\n",
    "    return doc_list\n",
    "\n",
    "\n",
    "def clean_text(doc):\n",
    "    '''cleans and lemmatizes a string by removing punc, characters, digits, and len(words) < 3'''\n",
    "    \n",
    "    stop_words = stopwords.words('english')\n",
    "    punct = ('!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~♪¿’')\n",
    "    remove_digits = str.maketrans('', '', digits)\n",
    "    wordnet_lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized = []\n",
    "    \n",
    "    doc = doc.split('\\n')\n",
    "    doc = ' '.join(doc)\n",
    "    doc = doc.split('-')\n",
    "    doc = ' '.join(doc)\n",
    "    doc = doc.split('...')\n",
    "    doc = ' '.join(doc)\n",
    "    doc = word_tokenize(doc)\n",
    "\n",
    "    a = [char for char in doc if char not in punct]\n",
    "    b = [w for w in a if w not in stop_words] \n",
    "    c = [w for w in b if len(w) > 3]\n",
    "    d = [x for x in c if not (x.isdigit() or x[0] == '-' and x[1:].isdigit())]\n",
    "\n",
    "    e = ' '.join(d)\n",
    "    f = e.lower()\n",
    "    g = f.translate(remove_digits)\n",
    "    cleaned = str(g)\n",
    "    doc = word_tokenize(cleaned)\n",
    "    \n",
    "    for val in doc:\n",
    "        doc_temp = wordnet_lemmatizer.lemmatize(val)\n",
    "        lemmatized.append(doc_temp)\n",
    "    doc = ' '.join(lemmatized)\n",
    "    \n",
    "    return doc\n",
    "\n",
    "def clean_and_return(docs_list):\n",
    "    \n",
    "    docs = []\n",
    "    for cc in docs_list:\n",
    "        cleaned_temp = clean_text(cc)\n",
    "        docs.append(cleaned_temp)\n",
    "        \n",
    "    return docs\n",
    "\n",
    "\n",
    "def lang_detect(doc_series):\n",
    "    \n",
    "    lang = []\n",
    "    for x in doc_series:\n",
    "        eng = 'en'\n",
    "        span = 'es'\n",
    "\n",
    "        try:\n",
    "            if detect(x) == eng:\n",
    "                lang.append(eng)\n",
    "            else:\n",
    "                lang.append(span)\n",
    "        except:\n",
    "            lang.append(None)\n",
    "            \n",
    "    return lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.read_csv('data/cc_1000_text.csv', encoding='utf-8')\n",
    "temp_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "temp = temp_df['text'].values\n",
    "temp = temp.tolist()\n",
    "type(temp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_list = clean_all_text(temp)\n",
    "type(docs_list)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_list = clean_and_return(docs_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df['cleaned'] = cleaned_list\n",
    "temp_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_series = pd.Series(temp_df['cleaned'].values)\n",
    "language = lang_detect(doc_series)\n",
    "temp_df['language'] = language\n",
    "english = temp_df[temp_df['language'] == 'en']\n",
    "spanish = temp_df[temp_df['language'] == 'es']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>channel</th>\n",
       "      <th>created_at</th>\n",
       "      <th>duration</th>\n",
       "      <th>lang</th>\n",
       "      <th>machine_id</th>\n",
       "      <th>ts</th>\n",
       "      <th>tui</th>\n",
       "      <th>tv</th>\n",
       "      <th>url</th>\n",
       "      <th>zip_url</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'$oid': '5bb2b5082c1ba60007fc013d'}</td>\n",
       "      <td>WBNX_HD_CW</td>\n",
       "      <td>{'$date': '2018-10-02T00:00:08.982Z'}</td>\n",
       "      <td>900000</td>\n",
       "      <td>dflt</td>\n",
       "      <td>ENSWERCCR7_8_3</td>\n",
       "      <td>{'$numberLong': '1538437500000'}</td>\n",
       "      <td>251536767</td>\n",
       "      <td>{'$date': '2018-10-01T23:45:00.000Z'}</td>\n",
       "      <td>https://s3.amazonaws.com/adm-mpeg-dash/gnvideo...</td>\n",
       "      <td>https://s3.amazonaws.com/adm-mpeg-dash/gnvideo...</td>\n",
       "      <td>2018-10-02 00:00:08.982</td>\n",
       "      <td>1538437621406\\n1835\\n[ KNOCK ON DOOR ]\\n\\n1538...</td>\n",
       "      <td>knock door knew only that still knock have doo...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    _id     channel  \\\n",
       "0  {'$oid': '5bb2b5082c1ba60007fc013d'}  WBNX_HD_CW   \n",
       "\n",
       "                              created_at  duration  lang      machine_id  \\\n",
       "0  {'$date': '2018-10-02T00:00:08.982Z'}    900000  dflt  ENSWERCCR7_8_3   \n",
       "\n",
       "                                 ts        tui  \\\n",
       "0  {'$numberLong': '1538437500000'}  251536767   \n",
       "\n",
       "                                      tv  \\\n",
       "0  {'$date': '2018-10-01T23:45:00.000Z'}   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://s3.amazonaws.com/adm-mpeg-dash/gnvideo...   \n",
       "\n",
       "                                             zip_url                     date  \\\n",
       "0  https://s3.amazonaws.com/adm-mpeg-dash/gnvideo...  2018-10-02 00:00:08.982   \n",
       "\n",
       "                                                text  \\\n",
       "0  1538437621406\\n1835\\n[ KNOCK ON DOOR ]\\n\\n1538...   \n",
       "\n",
       "                                             cleaned language  \n",
       "0  knock door knew only that still knock have doo...       en  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english = pd.read_csv('data/testenglish.csv', encoding='utf-8')\n",
    "#english.to_csv('data/testenglish.csv', encoding='utf-8', index=False)\n",
    "#spanish.to_csv('data/testspanish.csv', encoding='utf-8', index=False)\n",
    "english.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = english['cleaned'].values\n",
    "text = text.tolist()\n",
    "type(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_text(doc_list):\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(stop_words=stopwords.words('english'), ngram_range=(1, 3), lowercase=True) \n",
    "    tfidf_model = vectorizer.fit_transform(doc_list)\n",
    "    \n",
    "    return tfidf_model\n",
    "\n",
    "    \n",
    "def svd(doc_list):\n",
    "    \n",
    "    model = vectorize_text(doc_list)\n",
    "    \n",
    "    svd = TruncatedSVD(n_components=100, n_iter=7, random_state=42)\n",
    "    clf = svd.fit_transform(model) \n",
    "    \n",
    "    return clf\n",
    "\n",
    "def find_elbow(doc_list):\n",
    "    \n",
    "    clf = svd(doc_list)\n",
    "    \n",
    "    distortions = []\n",
    "    K = range(1,10)\n",
    "    for k in K:\n",
    "        kmeanModel = KMeans(n_clusters=k, n_jobs=2)\n",
    "        kmeanModel.fit(clf)\n",
    "        distortions.append(sum(np.min(cdist(clf, kmeanModel.cluster_centers_, 'euclidean'), axis=1)) / clf.shape[0])\n",
    "\n",
    "    plt.plot(K, distortions, 'bx-')\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('Distortion')\n",
    "    plt.title('The Elbow Method showing the optimal k')\n",
    "    plt.show()\n",
    "\n",
    "def KMeans_PCA_plot(doc_list, num_clusters=3, n_jobs=4):\n",
    "    \n",
    "    clf = svd(doc_list)\n",
    "    \n",
    "    km = KMeans(n_clusters=num_clusters, n_jobs=4) \n",
    "    km.fit(clf)\n",
    "\n",
    "    clusters = km.labels_.tolist()\n",
    "\n",
    "    pca = PCA(n_components=2).fit(clf)\n",
    "    data2D = pca.transform(clf)\n",
    "    plt.scatter(data2D[:,0], data2D[:,1], c=clusters, alpha=0.1)\n",
    "\n",
    "    centers2D = pca.transform(km.cluster_centers_)\n",
    "\n",
    "    plt.scatter(centers2D[:,0], centers2D[:,1], \n",
    "                marker='x', s=200, linewidths=3, c='r')\n",
    "    plt.title('(SVD REDUCED) Kmeans Clusters')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF - Kernel PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_model = vectorize_text(text)\n",
    "\n",
    "kpca = KernelPCA(n_components=5, kernel='rbf', gamma=15)\n",
    "X_kpca = kpca.fit_transform(tfidf_model)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.title('TFIDF - KernelPCA')\n",
    "plt.scatter(X_kpca[:, 0], X_kpca[:, 1], c='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_kpca.shape #n_samples, n_components(clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_model = vectorize_text(text)\n",
    "tf = tfidf_model.todense()\n",
    "\n",
    "pca = PCA(n_components=4)\n",
    "X_pca = pca.fit_transform(tf)\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(X_pca, np.zeros((891, 4)), c='k', cmap=plt.cm.rainbow)\n",
    "plt.title('First principal component after Linear PCA')\n",
    "plt.xlabel('PC1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_model = vectorize_text(text)\n",
    "tfidf_dense = tfidf_model.todense()\n",
    "\n",
    "pca = PCA(n_components=4)\n",
    "data2D = pca.fit_transform(tfidf_dense)\n",
    "\n",
    "#this array is one dimesional so we plot using\n",
    "plt.scatter(data2D[:,0], data2D[:,1], c='rgb', alpha=0.1)\n",
    "plt.title('PCA Reduction')\n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vecotrizer Pickled Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(decode_error=\"replace\")\n",
    "vec_train = vectorizer.fit_transform(for_model)\n",
    "\n",
    "#Save vectorizer.vocabulary_\n",
    "pickle.dump(vectorizer.vocabulary_,open(\"data/countvec_feature.pkl\", \"wb\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load it later\n",
    "transformer = TfidfTransformer()\n",
    "loaded_vec = CountVectorizer(decode_error=\"replace\",vocabulary=pickle.load(open(\"data/countvec_feature.pkl\", \"rb\")))\n",
    "tfidf = transformer.fit_transform(loaded_vec.fit_transform(for_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VADER Sentiment Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vader sentiment column ['positivity'] 0 - 1 for chi2score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words=stopwords.words('english'), ngram_range=(1, 3), lowercase=True)\n",
    "tfidf_model = tfidf.fit_transform(text)\n",
    "y = english['positivity']\n",
    "chi2score = chi2(X_tfidf, y)[0]\n",
    "\n",
    "%matplotlib inline\n",
    "plt.figure()\n",
    "scores = list(zip(tfidf.get_feature_names(), chi2score))\n",
    "chi2 = sorted(scores, key=lambda x:x[1])\n",
    "topchi2 = list(zip(*chi2[-20:]))\n",
    "x = range(len(topchi2[1]))\n",
    "labels = topchi2[0]\n",
    "plt.barh(x,topchi2[1], align='center', alpha=0.5)\n",
    "plt.plot(topchi2[1], x, '-o', markersize=5, alpha=0.8)\n",
    "plt.yticks(x, labels)\n",
    "plt.xlabel('$\\chi^2$')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Truncate Singular Value Decomposition (SVD) aka Latent Semantic Analysis (LSA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_model = vectorize_text(text)\n",
    "\n",
    "svd = TruncatedSVD(n_components=100, n_iter=7, random_state=42)\n",
    "clf = svd.fit_transform(tfidf_model) \n",
    "\n",
    "#this array is one dimesional so we plot using\n",
    "plt.scatter(clf[:,0], clf[:,1], c='rgb', alpha=0.1)\n",
    "plt.title('Truncated SVD Reduction')\n",
    "plt.show() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from gensim.models import Word2Vec\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.io import push_notebook, output_notebook\n",
    "from bokeh.models import ColumnDataSource, LabelSet\n",
    "\n",
    "model = Word2Vec(sentences=text, workers=4)\n",
    "X = model[model.wv.vocab]\n",
    "\n",
    "tsne = TSNE(n_components=2)\n",
    "X_tsne = tsne.fit_transform(X)\n",
    "\n",
    "plt.scatter(X_tsne[:, 0], X_tsne[:, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def interactive_tsne(text_labels, tsne_array):\n",
    "    '''makes an interactive scatter plot with text labels for each point'''\n",
    "\n",
    "    # define a dataframe to be used by bokeh context\n",
    "    bokeh_df = pd.DataFrame(tsne_array, text_labels, columns=['x','y'])\n",
    "    bokeh_df['text_labels'] = bokeh_df.index\n",
    "\n",
    "    # interactive controls to include to the plot\n",
    "    TOOLS=\"hover, zoom_in, zoom_out, box_zoom, undo, redo, reset, box_select\"\n",
    "\n",
    "    p = figure(tools=TOOLS, plot_width=700, plot_height=700)\n",
    "\n",
    "    # define data source for the plot\n",
    "    source = ColumnDataSource(bokeh_df)\n",
    "\n",
    "    # scatter plot\n",
    "    p.scatter('x', 'y', source=source, fill_alpha=0.6,\n",
    "              fill_color=\"#8724B5\",\n",
    "              line_color=None)\n",
    "\n",
    "    # text labels\n",
    "    labels = LabelSet(x='x', y='y', text='text_labels', y_offset=8,\n",
    "                      text_font_size=\"8pt\", text_color=\"#555555\",\n",
    "                      source=source, text_align='center')\n",
    "\n",
    "    p.add_layout(labels)\n",
    "\n",
    "    # show plot inline\n",
    "    output_notebook()\n",
    "    show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "element.interactive_tsne(model.wv.vocab.keys(), X_tsne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_elbow(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=stopwords.words('english'), ngram_range=(1, 3), lowercase=True) \n",
    "tfidf_model = vectorizer.fit_transform(text)\n",
    "\n",
    "# less noise without SVD\n",
    "# svd = TruncatedSVD(n_components=100, n_iter=7, random_state=42)\n",
    "# clf = svd.fit_transform(tfidf_model) \n",
    "\n",
    "kmeans = KMeans(n_clusters=5, n_init = 5, n_jobs = -1)\n",
    "km = kmeans.fit_transform(tfidf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = vectorizer.get_feature_names()\n",
    "common_words = kmeans.cluster_centers_.argsort()[:,-1:-11:-1]\n",
    "for num, centroid in enumerate(common_words):\n",
    "    print(str(num) + ' : ' + ', '.join(words[word] for word in centroid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_df = english\n",
    "kmeans_df['cluster'] = kmeans.labels_\n",
    "kmeans_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kmeans_df.to_csv('data/kmeans_clusters.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this array is one dimesional so we plot using\n",
    "plt.scatter(km[:,0], km[:,1], c='rgb', alpha=0.1)\n",
    "centers2D = kmeans.cluster_centers_\n",
    "\n",
    "plt.scatter(centers2D[:,0], centers2D[:,1], marker='x', s=200, linewidths=3, c='r')\n",
    "plt.title('TruncatedSVD + KMeans')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=100, n_iter=7, random_state=42)\n",
    "clf = svd.fit_transform(tfidf_model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in text:\n",
    "    tok = word_tokenize(text[1])\n",
    "    dictionary = corpora.Dictionary([(str(tok).split())])\n",
    "    corpus = [dictionary.doc2bow(t) for t in ([(str(tok).split())])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(seed=44)\n",
    "\n",
    "tok = word_tokenize(text[1])\n",
    "dictionary = corpora.Dictionary([(str(tok).split())])\n",
    "corpus = [dictionary.doc2bow(t) for t in ([(str(tok).split())])]\n",
    "\n",
    "# number of topics\n",
    "K=3\n",
    "\n",
    "# Run LDA model to extract topics\n",
    "lda = LdaModel(corpus=corpus, id2word=dictionary, num_topics=K, alpha='auto', passes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.show_topics(K, num_words=10, formatted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_data = gensimvis.prepare(lda, corpus, dictionary)\n",
    "pyLDAvis.enable_notebook()\n",
    "pyLDAvis.display(vis_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words=stopwords.words('english'), ngram_range=(1, 3), lowercase=True) \n",
    "tfidf_model = vectorizer.fit_transform(text)\n",
    "\n",
    "lda_tfidf = LatentDirichletAllocation(n_components=5, random_state=0)\n",
    "lda_model = lda_tfidf.fit_transform(tfidf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el35991406771042617841523836844\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el35991406771042617841523836844_data = {\"mdsDat\": {\"Freq\": [79.21598200628162, 11.16503961428292, 4.768427100389875, 4.321114662312557, 0.529436616733011], \"cluster\": [1, 1, 1, 1, 1], \"topics\": [1, 2, 3, 4, 5], \"x\": [-0.01317932301957139, 0.004132997157766014, 0.0032914221335480745, 0.003121383036899225, 0.0026335206913580735], \"y\": [0.00019111776740605082, 0.0030719135893338446, -0.0015642802355169466, -0.0011376252539425943, -0.0005611258672803568]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"Freq\": [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.9871483974016524, 2.358347732060877, 2.201960777282778, 1.8839282720135213, 2.0329054539198776, 1.733423871156396, 1.9396691938960486, 2.2887130890131524, 1.560767374150569, 1.470426085857463, 1.4442767138785413, 1.4719795207158737, 1.4340953319144736, 1.9187611893849308, 1.9922035625076122, 1.4248332169404574, 1.3286384600774162, 1.3242991426252315, 1.2813211490949168, 1.2431244087226923, 1.3847676356093508, 1.1939572461738097, 1.1842045142830377, 1.1874353080567426, 1.180593256369412, 1.2121655608000883, 1.1569545453649654, 1.1096866077341412, 1.1819905009923781, 1.135902253167701, 2.9913881594748495, 1.7209408318023018, 1.6566893011407584, 1.3754489165481474, 3.6946816315529363, 3.7324407464868576, 4.444688909160546, 2.180682783383496, 3.2697819571658666, 2.3415283815824046, 2.381077305647457, 1.7573914466840754, 2.1401466443456556, 2.300017689488283, 3.122503041548352, 1.9819736485958594, 2.1174909993464404, 2.220875103727903, 1.695676478533591, 1.7861972055524973, 1.8976725302854067, 2.0331549834339646, 1.7919490342723632, 1.7791306069325006, 1.7389652740988948, 0.16954715436772153, 0.14519278043714307, 0.26577522722513114, 0.09956072559405292, 0.09954261088129143, 0.09951795193592916, 0.099512563135908, 0.09579506470729371, 0.13991090431710862, 0.11750770448620701, 0.2492471156121486, 0.0823126366694574, 0.07610737593985505, 0.07610699777767027, 0.07609366176987686, 0.07608408240530819, 0.09853392498380514, 0.11089870005354201, 0.0756827014479007, 0.0687449086505617, 0.06405784807239501, 0.0640646092479136, 0.06414409792392776, 0.07456923695681868, 0.06447859276535832, 0.05481033637046916, 0.11442352208378538, 0.052629342024066376, 0.05263561518833675, 0.0526287092833704, 0.1476399634551364, 0.263737715502547, 0.05531636901949673, 0.24270002002738714, 0.26288763752124994, 0.38891828589705496, 0.09270504337575705, 0.09104053587015991, 0.13667535111447643, 0.29573068679341147, 0.13652846230613033, 0.09293270086624947, 0.13705351591730863, 0.11799803199550021, 0.1181633716971524, 0.11836466742193644, 0.10021127073735904, 0.10665186011806312, 0.12886209525156944, 0.11099796724400923, 0.1150166908605672, 0.10534754996122492, 0.10697079061661273, 0.04684864071800527, 0.04269898190737622, 0.046819076504941354, 0.04140800040055902, 0.022416635877214035, 0.016875817634055733, 0.015879804132370463, 0.015883691841122195, 0.015872676200622347, 0.015877461014539875, 0.015878490954855332, 0.01587476524913978, 0.01587427247773236, 0.01587301302415788, 0.01576492052972447, 0.01576123211915209, 0.015757644259578863, 0.01576512631550292, 0.01564702268468611, 0.015645284781700283, 0.01551972068800399, 0.015330892140610116, 0.029923565006360477, 0.015192322352018554, 0.010231678382421304, 0.010206807258107917, 0.025896285793981722, 0.009174265799431086, 0.009175415119179351, 0.009168877385534981, 0.009179097392301834, 0.017412108934084573, 0.019064560812858112, 0.014427980153056786, 0.017373958804920615, 0.0156695769258747, 0.036689804058855725, 0.03273455055733965, 0.027092856103687623, 0.02751892937326671, 0.02624745755280952, 0.021574628437393963, 0.018314707213415906, 0.016877368643817073, 0.01674213986676385, 0.019091562496543427, 0.02500178012899494, 0.03200413374652441, 0.012000904634866433, 0.012003746016604987, 0.01199890062204039, 0.011998791721597494, 0.011999349175981186, 0.011998130556892424, 0.011998833282424189, 0.012000078054634397, 0.012001032536881565, 0.012001283590958969, 0.011996804447240845, 0.011930626912777006, 0.011768008103826371, 0.011765424174095472, 0.012181853100273775, 0.029274199364408424, 0.011825807076642403, 0.01017849946852976, 0.017852909431506893, 0.025579118045929165, 0.0213995566745171, 0.02646728550230047, 0.016012185678198718, 0.026517920716921717, 0.022872980498617638, 0.01788859796485067, 0.01580838166701123, 0.027411047909370965, 0.013466952174361432, 0.016187497350561728, 0.01815553355944495, 0.013552399157840149, 0.014282927230436535, 0.014381076733184813, 0.013563318662627374, 0.0002791375735002092, 0.00027883797549471196, 0.00027834581736094525, 0.000279149959188203, 0.0002785315827458304, 0.0002787618347607057, 0.0002786358596226769, 0.0002781578302084743, 0.0002786555006304145, 0.0002785097376210039, 0.0002783420233348236, 0.0002784537573766698, 0.0002783261548195601, 0.00027786063821805864, 0.00027802079462159836, 0.00027858324576063016, 0.00027815716749304045, 0.0002786430480769952, 0.0002787245575815347, 0.0002784411843856113, 0.0002784631337981627, 0.00027803683224778973, 0.00027888384820862606, 0.00027845927883397994, 0.0002788885030627821, 0.00027812168503271533, 0.000278886606089374, 0.0002779828839944615, 0.0002789334553728873, 0.00027825569501125524, 0.0002786943310412029, 0.0002786686817881749, 0.00027868755023142716, 0.0002790462784651797, 0.0002788397720833805, 0.0002789413201866162, 0.0002785806287737218, 0.0002786157065218817, 0.0002788982194008317, 0.00027883084245712537, 0.0002790587296946691, 0.00027880375305469303, 0.00027893454670206263, 0.0002790017385461074, 0.0002790806495734514, 0.0002792543820124389, 0.0002790296135697823, 0.00027911749894993037, 0.0002789479346199087, 0.0002789328455704532, 0.00027903374066926386, 0.00027927827462763486, 0.00027903940573696, 0.00027911131758082667, 0.00027909666996334673, 0.0002791712983539217, 0.0002793453118727885, 0.0002795846330018102, 0.00027919977728630785, 0.00027903975371489326, 0.0002791609128728927, 0.00027905204625720283, 0.0002791360235951651, 0.0002791967774976635, 0.00027907166323254217, 0.0002791493339305442, 0.0002790856496153265, 0.00027962452139609526, 0.00027961092214774517, 0.00027960910305419164, 0.0002793839172250156, 0.0002793388378832916, 0.00027942977165426917, 0.0002794344820169754, 0.00027943909634771803, 0.0002792283186867291, 0.0002793800567111464, 0.00027933164670292235, 0.00027926249061418937, 0.00027923011213712136, 0.00027952023553742475, 0.00027955525956750975, 0.0002795311100382106, 0.0002794267323004506, 0.00027940425256699577, 0.00027934799404277766, 0.0002794518223607007, 0.0002794057652241061, 0.00027965192265412125, 0.0002794163279400218, 0.0002793551774296037, 0.0002793586303598231, 0.00027951371186616867, 0.00027933271576812346, 0.000279299905938234, 0.00028028157131248485, 0.00028023237777351115, 0.0002801650575531616, 0.00028004533746158367, 0.0002798936279447545, 0.00027987588081900634, 0.0002797451586197935, 0.000279691723729708, 0.00027962463273962135, 0.0002796198059166211, 0.00027958965620937553, 0.0002795493210623901, 0.0002795111323710662, 0.0002795075674288639, 0.0002794910314672808, 0.00027947724117697675, 0.0002794546280493044], \"Term\": [\"steve\", \"applause\", \"teller\", \"penn\", \"cheering\", \"penn teller\", \"cheering applause\", \"heart\", \"andrew\", \"magic\", \"birthday\", \"alyson\", \"inch\", \"doug\", \"infection\", \"trick\", \"taryn\", \"york\", \"answer\", \"suit\", \"laughter\", \"name\", \"magician\", \"card\", \"name something\", \"joint\", \"harvey\", \"excited\", \"wheel\", \"heart heart\", \"york\", \"blake\", \"erin\", \"york city\", \"night\", \"daly\", \"dave\", \"kelly\", \"love love\", \"broadway\", \"neighborhood\", \"black\", \"patient\", \"week\", \"city\", \"last\", \"love love love\", \"cool\", \"reporter\", \"coach\", \"judge\", \"queen kelly\", \"trauma\", \"elton\", \"jennifer\", \"conrad\", \"smoker\", \"harry\", \"say\", \"talk\", \"love\", \"cheer applause\", \"cheer\", \"guy\", \"like\", \"know\", \"right\", \"going\", \"okay\", \"come\", \"laugh\", \"year\", \"look\", \"well\", \"yeah\", \"really\", \"time\", \"want\", \"take\", \"make\", \"star\", \"good\", \"people\", \"said\", \"think\", \"taryn\", \"name something\", \"penn teller\", \"inch away\", \"kiko pastur\", \"pastur\", \"kiko\", \"survey said\", \"magician\", \"heart heart\", \"cheering applause\", \"steve name\", \"richmond hill\", \"card trick\", \"heart heart heart\", \"foot inch away\", \"spade\", \"carl\", \"foot inch\", \"mary ellen\", \"autobiography\", \"constellation\", \"laurence\", \"richmond\", \"filter\", \"casey price\", \"harvey\", \"impossible thing\", \"cardistry\", \"hill ontario canada\", \"doug\", \"penn\", \"good answer\", \"cheering\", \"teller\", \"steve\", \"iphone\", \"survey\", \"birthday\", \"applause\", \"andrew\", \"applause applause\", \"heart\", \"inch\", \"alyson\", \"magic\", \"answer\", \"trick\", \"right\", \"laughter\", \"yeah\", \"name\", \"thank\", \"judy\", \"kripke\", \"judge judy\", \"rabbit\", \"koothrappali\", \"personal space\", \"confetto\", \"highly unlikely\", \"rich parent\", \"lost kripke\", \"hypochondria\", \"valentino\", \"rajesh\", \"like lost kripke\", \"like lost\", \"look like lost\", \"confetti\", \"wolowitz\", \"rabies\", \"singular\", \"three different\", \"unlikely\", \"flag\", \"terrific\", \"happy valentine\", \"yeah ahead\", \"valentine\", \"intelligent koothrappali\", \"good sign wait\", \"highly unlikely terrific\", \"rabies rabbit highly\", \"vaseline\", \"sheldon\", \"highly\", \"switzerland\", \"relationship\", \"sheena\", \"vowel\", \"vanna\", \"ricky\", \"puzzle\", \"melissa\", \"inside edition\", \"consonant\", \"three second\", \"thanksgiving\", \"simpson\", \"enbrel\", \"second event buzzer\", \"brandon excited\", \"give wheel\", \"puzzle vanna\", \"event buzzer\", \"puzzle three\", \"three money\", \"puzzle three second\", \"buzzer ricky\", \"bonus round\", \"three second event\", \"buzzer sheena\", \"bolivia\", \"peru\", \"beeper\", \"category\", \"second event\", \"caption sponsorship\", \"edition\", \"buzzer\", \"deborah\", \"wheel\", \"spin\", \"joint\", \"humira\", \"joint damage\", \"solve\", \"infection\", \"kanye west\", \"kanye\", \"excited\", \"joint pain\", \"damage\", \"event\", \"worth\", \"vitac com karen\", \"driving running\", \"property plant hisur\", \"returning star returning\", \"ready assuming want\", \"watch negativelies revolution\", \"pay original\", \"right right root\", \"court trooper court\", \"face suspect\", \"monthly premium telehealth\", \"okay patrolman okay\", \"say sore otherwtse\", \"kevin investigator investigator\", \"veggie judge judy\", \"stop right timendo\", \"hanging hisis asking\", \"org revolution\", \"lauyou heavy\", \"coming traffic ramming\", \"shram trooper bryce\", \"affordable monthly premium\", \"right wait find\", \"behind locked jail\", \"bigger banking yydty\", \"life state\", \"coming suspect speeding\", \"andhe allowed\", \"thin alexis aifferent\", \"heading wrong truck\", \"help find plan\", \"traffic ramming\", \"year wedding anniversary\", \"com carlo\", \"category vanna already\", \"hope prayer nation\", \"dwepty life danger\", \"hear zoning commission\", \"hope prayer\", \"could jumping\", \"amazing group people\", \"happily married\", \"bunch want jump\", \"safe jump want\", \"diving protect head\", \"would ortega freshman\", \"issue mean\", \"mold test mold\", \"part storm expect\", \"doctor jeez\", \"moved chance\", \"cheese emergency like\", \"dotcom cheering\", \"wasas mamathth teaeachcherer\", \"jovanna head\", \"esperenza severely\", \"okay property well\", \"place least three\", \"growth america heartland\", \"shooting police looking\", \"damage nothing\", \"questioning hurt\", \"night night night\", \"distribution broadcasting revolution\", \"cluster crime crime\", \"good soaking tonight\", \"letter judge\", \"yummy yummy trojan\", \"college career drinking\", \"away process\", \"fourth overtime touchdown\", \"drive denise\", \"county free\", \"renew portion confirm\", \"renter also\", \"spin vowel right\", \"cell phone across\", \"thanks calling\", \"emotional still\", \"mind bermea never\", \"watch rain thursday\", \"retraction\", \"mall need save\", \"game game stadium\", \"thanksgiving beeping\", \"week take additional\", \"rolled house\", \"rejoin company want\", \"younger well\", \"married year sudden\", \"protein pack protein\", \"bullts like somebody\", \"reason suit\", \"engineer exactly pump\", \"vega happening\", \"time\", \"deborah\", \"know\", \"phil\", \"think\", \"kripke\", \"rabbit\", \"like\", \"laugh\", \"come\", \"america\", \"take\", \"good\", \"okay\", \"shower\", \"laughter\", \"company called bird\"], \"Total\": [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.99795223201717, 2.369110233670026, 2.212707041456087, 1.8946716998534088, 2.045476679534148, 1.7441839504944698, 1.9520659173878618, 2.303415043020438, 1.5716028391852677, 1.4811509359741901, 1.4551227137132094, 1.4831941103474835, 1.4453668450575645, 1.9339200448941227, 2.008032532233258, 1.4362996318324743, 1.3393541470203012, 1.335050870670777, 1.2921388768452735, 1.2538886898061583, 1.3968754470044074, 1.2047064766995221, 1.1949135664940733, 1.198204528318744, 1.1913204300612752, 1.223439089817981, 1.1677469568739918, 1.1204306757103764, 1.1934668048304564, 1.147015177638026, 3.0228800657635597, 1.7389967206504333, 1.6735115343005784, 1.389498630140425, 3.7761155798138835, 3.832530832446576, 4.581349592284425, 2.215421263409702, 3.350246922474777, 2.3835297742905817, 2.4255047193369523, 1.7828291088139128, 2.183005402670812, 2.354681031809579, 3.244214866534613, 2.023795026612368, 2.16905226737987, 2.2975187520680445, 1.7246573511289984, 1.8239479492228483, 1.9512727197882447, 2.1081307138207923, 1.832439106444102, 1.8478446166873645, 1.8084103383496304, 0.20909360774775562, 0.18458410649973617, 0.357711829232803, 0.13936649150279867, 0.13953004911595154, 0.13954786887602494, 0.13962185041731592, 0.13520697323364478, 0.2014072240299558, 0.1698594641773718, 0.36773263459227457, 0.12177406571167815, 0.11571451276017415, 0.11579211518071743, 0.11583885270180859, 0.11590948116361555, 0.1516971994100468, 0.17265729035614952, 0.1186540722283492, 0.10819333656654281, 0.10332172945350507, 0.10335647926590948, 0.10352188446368454, 0.12233139871152833, 0.1097938005054644, 0.09420094036193762, 0.1986572377675975, 0.09206974201666732, 0.09214109034155815, 0.09215093159763302, 0.26195508572573306, 0.49628307589126197, 0.09706635472218533, 0.5076919875275443, 0.5859290089181642, 0.9792486195531176, 0.17781275141018643, 0.1768824031494067, 0.3384788192447139, 1.899031478569827, 0.42900069252585554, 0.1980782817436773, 0.5337392021877526, 0.4043171796048059, 0.4059795939499878, 0.7341560064486818, 0.42597784107117814, 0.6509992337132294, 4.581349592284425, 1.127612238344815, 3.244214866534613, 1.0516093629276546, 1.772010322318375, 0.09374090360707112, 0.0854507105726356, 0.0940596964151256, 0.10204724770639427, 0.06965938001875317, 0.0596175498381829, 0.05845594927629098, 0.05848372905929603, 0.058505501754785375, 0.058540540872949104, 0.05858283242498169, 0.05856951915973089, 0.058569848071746845, 0.05871599892070429, 0.06094275117999619, 0.060940155816166366, 0.06202822916518935, 0.06317060078563698, 0.06330369630890594, 0.06444304741565852, 0.06915869192129542, 0.07018233470174491, 0.1395213824914019, 0.07251843712127648, 0.05302392892933323, 0.055642501195962264, 0.14160248543909307, 0.05177403830721423, 0.0517936033860271, 0.05176786918092598, 0.051826893645953366, 0.11426429848474645, 0.1730669456759574, 0.11901607175963758, 0.19048825486755105, 0.24827962005084012, 0.08027393876752696, 0.07807473089765021, 0.0702624923908203, 0.07650717716217655, 0.07932824642064766, 0.0699095730730706, 0.0640124224620769, 0.05978223189779429, 0.062313121834610546, 0.07556576951894244, 0.10560963662956986, 0.14425987144639985, 0.05482979647909466, 0.05485069341357928, 0.05484109752288492, 0.054854285637852315, 0.0548637681589841, 0.05486468601035964, 0.0548873666988382, 0.054895591169132375, 0.05492807939283234, 0.05495448396099004, 0.054953773239376, 0.054737278065249084, 0.05469731187568026, 0.05479055751695322, 0.060165685635282955, 0.14555367251207724, 0.06016077881162539, 0.05314732613912281, 0.09415388374372075, 0.14086997611948898, 0.11947856138293746, 0.17582054852156007, 0.09329396192246314, 0.23764038270906487, 0.19502646939583224, 0.12993438604231708, 0.11241193298113564, 0.5283523547829141, 0.08571531758054574, 0.19843249805789015, 0.3718087816995372, 0.1271095794753035, 0.277385776543252, 0.397462490883113, 0.3066729306185613, 0.045232114407547507, 0.04518692412004601, 0.04512280287278902, 0.04527687576167956, 0.045177559997304335, 0.04522061723363748, 0.045205072306546516, 0.04513213978772117, 0.04521502151124056, 0.045196783630224314, 0.04517099277275932, 0.04518915842993012, 0.04516954502343987, 0.04509483817823781, 0.045123305641384025, 0.04521781285798873, 0.045152050436092814, 0.04523259117460245, 0.0452464623611865, 0.04520100430539789, 0.045206360619227635, 0.04513776426371233, 0.04527585881845945, 0.04520749903688686, 0.04528022297941387, 0.04515638040013712, 0.045280973708554835, 0.04513599580110513, 0.04529343648832111, 0.04518497824795172, 0.04525827445407044, 0.04525493505758836, 0.0452586016138122, 0.04532687763091538, 0.04529019335399025, 0.04531424863786879, 0.04524095358299777, 0.045251155637298625, 0.0453361831945046, 0.045318884588128897, 0.04539637655116284, 0.04531773454738317, 0.04536626677066398, 0.04539089638571615, 0.04543149184739906, 0.045517614050319455, 0.04542427076178461, 0.045464938949236595, 0.045393204837435766, 0.04539653573667421, 0.045466235424757945, 0.045612493707982885, 0.0454888204173825, 0.045556917926561954, 0.04554954304910123, 0.04562774752691159, 0.0458263490819167, 0.04614849384158674, 0.0457696436139696, 0.045569490702749224, 0.045747224762886875, 0.04558726301099317, 0.04575099100258813, 0.045890763152938246, 0.045635982341982934, 0.04580979006821865, 0.04569614721763373, 0.04715340029971772, 0.04713709527118115, 0.04736206149551228, 0.04670474619463962, 0.04659997333291276, 0.04700165221201061, 0.04702757477798189, 0.04705693067051728, 0.046192640338855444, 0.04693037974642501, 0.0467990745085355, 0.04641618129886093, 0.046277146788344437, 0.04808927949057186, 0.048492071587439574, 0.04834936997875954, 0.047653942295987246, 0.04750832559675043, 0.04712652376094588, 0.048051955547044466, 0.04772949245157655, 0.0518671496599179, 0.04808796176642068, 0.04734046429680038, 0.04745189475892231, 0.05044297912492343, 0.04754842348841084, 0.04702356222517901, 2.16905226737987, 0.11947856138293746, 3.832530832446576, 0.6237953040968833, 1.8084103383496304, 0.0854507105726356, 0.10204724770639427, 3.7761155798138835, 2.4255047193369523, 2.3835297742905817, 0.44321725855710103, 1.7246573511289984, 2.1081307138207923, 3.350246922474777, 0.6528082367216886, 1.127612238344815, 0.050088747344931524], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.2294, 0.2284, 0.2281, 0.2273, 0.2268, 0.2268, 0.2266, 0.2266, 0.2261, 0.2257, 0.2255, 0.2254, 0.2252, 0.2251, 0.2251, 0.225, 0.225, 0.2249, 0.2246, 0.2244, 0.2243, 0.224, 0.224, 0.224, 0.2239, 0.2237, 0.2237, 0.2234, 0.2233, 0.2233, 0.2225, 0.2226, 0.2229, 0.2228, 0.2112, 0.2065, 0.2027, 0.2172, 0.2087, 0.2152, 0.2145, 0.2186, 0.2132, 0.2095, 0.1948, 0.2121, 0.2089, 0.1991, 0.216, 0.2121, 0.2051, 0.1968, 0.2106, 0.1951, 0.1938, 1.9827, 1.9523, 1.8953, 1.856, 1.8547, 1.8543, 1.8537, 1.8478, 1.8281, 1.8239, 1.8035, 1.8007, 1.7734, 1.7727, 1.7721, 1.7714, 1.7609, 1.7497, 1.7427, 1.7389, 1.7143, 1.7141, 1.7137, 1.6974, 1.6601, 1.6508, 1.6407, 1.6331, 1.6325, 1.6322, 1.619, 1.5602, 1.6301, 1.4543, 1.3909, 1.269, 1.5411, 1.5282, 1.2855, 0.3327, 1.0475, 1.4356, 0.8328, 0.9609, 0.9581, 0.3674, 0.7453, 0.3834, -1.3786, -0.126, -1.1472, -0.1084, -0.6149, 2.3495, 2.3494, 2.3455, 2.1412, 1.9093, 1.7811, 1.7399, 1.7397, 1.7386, 1.7383, 1.7377, 1.7377, 1.7376, 1.7351, 1.691, 1.6908, 1.6729, 1.6551, 1.6455, 1.6275, 1.5489, 1.5219, 1.5036, 1.4801, 1.3979, 1.3473, 1.3442, 1.3127, 1.3124, 1.3122, 1.3122, 1.1618, 0.8373, 0.9331, 0.6485, 0.2803, 2.3587, 2.2724, 2.1887, 2.1191, 2.0356, 1.966, 1.8903, 1.8769, 1.8274, 1.7659, 1.7009, 1.6359, 1.6224, 1.6223, 1.622, 1.6218, 1.6217, 1.6215, 1.6212, 1.6211, 1.6206, 1.6202, 1.6198, 1.6182, 1.6052, 1.6033, 1.5445, 1.5378, 1.5149, 1.4889, 1.4789, 1.4356, 1.4219, 1.2481, 1.3793, 0.9487, 0.9985, 1.1588, 1.18, 0.1828, 1.2909, 0.6354, 0.1223, 0.9032, 0.1753, -0.1775, 0.0232, 0.1533, 0.1532, 0.1528, 0.1523, 0.1523, 0.1522, 0.1521, 0.152, 0.1519, 0.1518, 0.1518, 0.1518, 0.1517, 0.1517, 0.1517, 0.1516, 0.1515, 0.1515, 0.1515, 0.1514, 0.1514, 0.1514, 0.1514, 0.1514, 0.1513, 0.1513, 0.1513, 0.1512, 0.1512, 0.1511, 0.1511, 0.1511, 0.1511, 0.1508, 0.1509, 0.1507, 0.1511, 0.151, 0.1501, 0.1502, 0.1493, 0.1502, 0.1496, 0.1493, 0.1487, 0.1474, 0.1486, 0.148, 0.149, 0.1489, 0.1477, 0.1454, 0.1472, 0.146, 0.1461, 0.1447, 0.1409, 0.1348, 0.1417, 0.1455, 0.142, 0.1451, 0.1418, 0.139, 0.1441, 0.1406, 0.1429, 0.1134, 0.1137, 0.1089, 0.1221, 0.1242, 0.1159, 0.1154, 0.1148, 0.1326, 0.1173, 0.1199, 0.1279, 0.1307, 0.0934, 0.0852, 0.088, 0.1021, 0.1051, 0.113, 0.0939, 0.1005, 0.0182, 0.093, 0.1085, 0.1061, 0.0456, 0.104, 0.115, -3.7129, -0.8142, -4.2825, -2.4675, -3.5324, -0.4802, -0.6582, -4.2694, -3.827, -3.8096, -2.1274, -3.4862, -3.6872, -4.1504, -2.515, -3.0616, 0.0524], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -9.0767, -9.3131, -9.3817, -9.5377, -9.4616, -9.621, -9.5085, -9.3431, -9.7259, -9.7855, -9.8035, -9.7845, -9.8105, -9.5194, -9.4818, -9.817, -9.8869, -9.8902, -9.9232, -9.9534, -9.8455, -9.9938, -10.002, -9.9993, -10.005, -9.9787, -10.0253, -10.067, -10.0039, -10.0436, -9.0753, -9.6282, -9.6662, -9.8523, -8.8642, -8.854, -8.6794, -9.3914, -8.9863, -9.3203, -9.3035, -9.6072, -9.4102, -9.3381, -9.0324, -9.487, -9.4208, -9.3732, -9.643, -9.591, -9.5304, -9.4615, -9.5878, -9.5949, -9.6178, -9.9863, -10.1414, -9.5368, -10.5187, -10.5188, -10.5191, -10.5191, -10.5572, -10.1784, -10.3529, -9.601, -10.7089, -10.7873, -10.7873, -10.7875, -10.7876, -10.529, -10.4108, -10.7929, -10.889, -10.9596, -10.9595, -10.9583, -10.8077, -10.9531, -11.1156, -10.3795, -11.1562, -11.156, -11.1562, -10.1247, -9.5445, -11.1064, -9.6276, -9.5477, -9.1561, -10.59, -10.6081, -10.2018, -9.43, -10.2029, -10.5876, -10.1991, -10.3488, -10.3474, -10.3457, -10.5121, -10.4499, -10.2607, -10.4099, -10.3744, -10.4622, -10.4469, -10.4217, -10.5145, -10.4224, -10.5452, -11.1589, -11.4428, -11.5036, -11.5034, -11.5041, -11.5038, -11.5037, -11.5039, -11.504, -11.504, -11.5109, -11.5111, -11.5113, -11.5109, -11.5184, -11.5185, -11.5265, -11.5388, -10.87, -11.5479, -11.9432, -11.9456, -11.0146, -12.0523, -12.0521, -12.0528, -12.0517, -11.4115, -11.3208, -11.5995, -11.4137, -11.5169, -10.5677, -10.6817, -10.8709, -10.8553, -10.9026, -11.0986, -11.2625, -11.3442, -11.3522, -11.2209, -10.9512, -10.7043, -11.6852, -11.6849, -11.6853, -11.6854, -11.6853, -11.6854, -11.6853, -11.6852, -11.6852, -11.6851, -11.6855, -11.691, -11.7048, -11.705, -11.6702, -10.7934, -11.6999, -11.8499, -11.288, -10.9284, -11.1068, -10.8942, -11.3968, -10.8923, -11.0402, -11.286, -11.4096, -10.8592, -11.5699, -11.3859, -11.2712, -11.5636, -11.5111, -11.5042, -11.5628, -13.3468, -13.3478, -13.3496, -13.3467, -13.3489, -13.3481, -13.3486, -13.3503, -13.3485, -13.349, -13.3496, -13.3492, -13.3497, -13.3513, -13.3508, -13.3487, -13.3503, -13.3485, -13.3482, -13.3492, -13.3492, -13.3507, -13.3477, -13.3492, -13.3476, -13.3504, -13.3477, -13.3509, -13.3475, -13.3499, -13.3483, -13.3484, -13.3484, -13.3471, -13.3478, -13.3475, -13.3487, -13.3486, -13.3476, -13.3479, -13.347, -13.3479, -13.3475, -13.3472, -13.347, -13.3463, -13.3471, -13.3468, -13.3474, -13.3475, -13.3471, -13.3462, -13.3471, -13.3468, -13.3469, -13.3466, -13.346, -13.3452, -13.3465, -13.3471, -13.3467, -13.3471, -13.3468, -13.3465, -13.347, -13.3467, -13.3469, -13.345, -13.3451, -13.3451, -13.3459, -13.346, -13.3457, -13.3457, -13.3457, -13.3464, -13.3459, -13.3461, -13.3463, -13.3464, -13.3454, -13.3453, -13.3453, -13.3457, -13.3458, -13.346, -13.3456, -13.3458, -13.3449, -13.3458, -13.346, -13.346, -13.3454, -13.3461, -13.3462, -13.3427, -13.3428, -13.3431, -13.3435, -13.344, -13.3441, -13.3446, -13.3448, -13.345, -13.345, -13.3451, -13.3453, -13.3454, -13.3454, -13.3455, -13.3455, -13.3456]}, \"token.table\": {\"Topic\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [1.0531684295755923, 0.6742205844963337, 0.8441987931062914, 0.6751506384069325, 1.3765655801055734, 1.1950918526748446, 1.150088425268533, 0.9959997997520864, 0.797518956929576, 0.8390916788926067, 0.8173680310874949, 0.7490351281502587, 1.1466680446365805, 1.0245555655601428, 0.8345820570409178, 0.9038702198389021, 0.9027628438132113, 0.9487077755132103, 0.7196840488420908, 0.8925139427889898, 0.8394047266935272, 0.7158834398188436, 0.8682760000461862, 1.0436967567581228, 0.6962335558940232, 0.8245706487624274, 0.8868296795606503, 1.0592896100381417, 0.9161681402863626, 0.9924310375318247, 1.2725861458972785, 0.7466285166061031, 1.362108313786439, 1.096522519105967, 0.9509234467217224, 0.6872272630864109, 0.9777671972557003, 0.895456385580065, 0.6918658771089862, 1.091441452524474, 1.603089977485126, 0.8300777154777594, 0.9882423732149404, 0.7739106205375357, 0.8731051668129645, 1.0823420876076717, 0.837895110238998, 1.5318434170222173, 0.8563499087824273, 1.0249720501483992, 1.0211911255553798, 1.159650639410058, 0.8718280450823983, 1.1286615968372797, 1.1059436885464922, 0.9220616902956984, 0.8368806146657469, 1.5361001184227328, 0.870504320454298, 1.034168917831086, 0.8493719416693114, 0.9247229679347728, 1.121812511424927, 1.000683055574055, 1.0555918474713801], \"Term\": [\"applause\", \"black\", \"blake\", \"broadway\", \"card\", \"cheer\", \"cheer applause\", \"city\", \"coach\", \"come\", \"conrad\", \"cool\", \"daly\", \"dave\", \"elton\", \"erin\", \"going\", \"good\", \"guy\", \"harry\", \"jennifer\", \"judge\", \"kelly\", \"know\", \"last\", \"laugh\", \"laughter\", \"like\", \"look\", \"love\", \"love love\", \"love love love\", \"magic\", \"make\", \"name\", \"neighborhood\", \"night\", \"okay\", \"patient\", \"people\", \"phil\", \"queen kelly\", \"really\", \"reporter\", \"right\", \"said\", \"say\", \"shower\", \"smoker\", \"star\", \"steve\", \"take\", \"talk\", \"thank\", \"think\", \"time\", \"trauma\", \"trick\", \"want\", \"week\", \"well\", \"yeah\", \"year\", \"york\", \"york city\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [4, 1, 2, 5, 3]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el35991406771042617841523836844\", ldavis_el35991406771042617841523836844_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el35991406771042617841523836844\", ldavis_el35991406771042617841523836844_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el35991406771042617841523836844\", ldavis_el35991406771042617841523836844_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=            Freq  cluster  topics         x         y\n",
       "topic                                                \n",
       "3      79.215982        1       1 -0.013179  0.000191\n",
       "0      11.165040        1       2  0.004133  0.003072\n",
       "1       4.768427        1       3  0.003291 -0.001564\n",
       "4       4.321115        1       4  0.003121 -0.001138\n",
       "2       0.529437        1       5  0.002634 -0.000561, topic_info=       Category      Freq                   Term     Total  loglift  logprob\n",
       "term                                                                        \n",
       "512940  Default  0.000000                  steve  0.000000  30.0000  30.0000\n",
       "23377   Default  1.000000               applause  1.000000  29.0000  29.0000\n",
       "540212  Default  0.000000                 teller  0.000000  28.0000  28.0000\n",
       "391396  Default  0.000000                   penn  0.000000  27.0000  27.0000\n",
       "85054   Default  0.000000               cheering  0.000000  26.0000  26.0000\n",
       "391413  Default  0.000000            penn teller  0.000000  25.0000  25.0000\n",
       "85059   Default  0.000000      cheering applause  0.000000  24.0000  24.0000\n",
       "237226  Default  0.000000                  heart  0.000000  23.0000  23.0000\n",
       "17199   Default  0.000000                 andrew  0.000000  22.0000  22.0000\n",
       "322482  Default  0.000000                  magic  0.000000  21.0000  21.0000\n",
       "51258   Default  0.000000               birthday  0.000000  20.0000  20.0000\n",
       "15216   Default  0.000000                 alyson  0.000000  19.0000  19.0000\n",
       "257219  Default  0.000000                   inch  0.000000  18.0000  18.0000\n",
       "147038  Default  0.000000                   doug  0.000000  17.0000  17.0000\n",
       "259368  Default  0.000000              infection  0.000000  16.0000  16.0000\n",
       "571788  Default  0.000000                  trick  0.000000  15.0000  15.0000\n",
       "536163  Default  0.000000                  taryn  0.000000  14.0000  14.0000\n",
       "626942  Default  2.000000                   york  2.000000  13.0000  13.0000\n",
       "19878   Default  0.000000                 answer  0.000000  12.0000  12.0000\n",
       "523462  Default  0.000000                   suit  0.000000  11.0000  11.0000\n",
       "292810  Default  1.000000               laughter  1.000000  10.0000  10.0000\n",
       "356160  Default  1.000000                   name  1.000000   9.0000   9.0000\n",
       "322637  Default  0.000000               magician  0.000000   8.0000   8.0000\n",
       "73638   Default  0.000000                   card  0.000000   7.0000   7.0000\n",
       "356709  Default  0.000000         name something  0.000000   6.0000   6.0000\n",
       "271187  Default  0.000000                  joint  0.000000   5.0000   5.0000\n",
       "233746  Default  0.000000                 harvey  0.000000   4.0000   4.0000\n",
       "169308  Default  0.000000                excited  0.000000   3.0000   3.0000\n",
       "606214  Default  0.000000                  wheel  0.000000   2.0000   2.0000\n",
       "237361  Default  0.000000            heart heart  0.000000   1.0000   1.0000\n",
       "...         ...       ...                    ...       ...      ...      ...\n",
       "326131   Topic5  0.000280         mall need save  0.048349   0.0880 -13.3453\n",
       "204021   Topic5  0.000279      game game stadium  0.047654   0.1021 -13.3457\n",
       "544782   Topic5  0.000279   thanksgiving beeping  0.047508   0.1051 -13.3458\n",
       "600889   Topic5  0.000279   week take additional  0.047127   0.1130 -13.3460\n",
       "455491   Topic5  0.000279           rolled house  0.048052   0.0939 -13.3456\n",
       "438355   Topic5  0.000279    rejoin company want  0.047729   0.1005 -13.3458\n",
       "627603   Topic5  0.000280           younger well  0.051867   0.0182 -13.3449\n",
       "329461   Topic5  0.000279    married year sudden  0.048088   0.0930 -13.3458\n",
       "420582   Topic5  0.000279   protein pack protein  0.047340   0.1085 -13.3460\n",
       "65578    Topic5  0.000279   bullts like somebody  0.047452   0.1061 -13.3460\n",
       "435040   Topic5  0.000280            reason suit  0.050443   0.0456 -13.3454\n",
       "159564   Topic5  0.000279  engineer exactly pump  0.047548   0.1040 -13.3461\n",
       "584846   Topic5  0.000279         vega happening  0.047024   0.1150 -13.3462\n",
       "555469   Topic5  0.000280                   time  2.169052  -3.7129 -13.3427\n",
       "130289   Topic5  0.000280                deborah  0.119479  -0.8142 -13.3428\n",
       "282937   Topic5  0.000280                   know  3.832531  -4.2825 -13.3431\n",
       "396637   Topic5  0.000280                   phil  0.623795  -2.4675 -13.3435\n",
       "547507   Topic5  0.000280                  think  1.808410  -3.5324 -13.3440\n",
       "287580   Topic5  0.000280                 kripke  0.085451  -0.4802 -13.3441\n",
       "426523   Topic5  0.000280                 rabbit  0.102047  -0.6582 -13.3446\n",
       "301361   Topic5  0.000280                   like  3.776116  -4.2694 -13.3448\n",
       "291938   Topic5  0.000280                  laugh  2.425505  -3.8270 -13.3450\n",
       "98658    Topic5  0.000280                   come  2.383530  -3.8096 -13.3450\n",
       "15959    Topic5  0.000280                america  0.443217  -2.1274 -13.3451\n",
       "530813   Topic5  0.000280                   take  1.724657  -3.4862 -13.3453\n",
       "216785   Topic5  0.000280                   good  2.108131  -3.6872 -13.3454\n",
       "375655   Topic5  0.000280                   okay  3.350247  -4.1504 -13.3454\n",
       "484901   Topic5  0.000279                 shower  0.652808  -2.5150 -13.3455\n",
       "292810   Topic5  0.000279               laughter  1.127612  -3.0616 -13.3455\n",
       "103711   Topic5  0.000279    company called bird  0.050089   0.0524 -13.3456\n",
       "\n",
       "[333 rows x 6 columns], token_table=        Topic      Freq            Term\n",
       "term                                   \n",
       "23377       1  1.053168        applause\n",
       "51653       1  0.674221           black\n",
       "52011       1  0.844199           blake\n",
       "62226       1  0.675151        broadway\n",
       "73638       1  1.376566            card\n",
       "84857       1  1.195092           cheer\n",
       "84862       1  1.150088  cheer applause\n",
       "89914       1  0.996000            city\n",
       "95471       1  0.797519           coach\n",
       "98658       1  0.839092            come\n",
       "108015      1  0.817368          conrad\n",
       "111303      1  0.749035            cool\n",
       "124910      1  1.146668            daly\n",
       "127154      1  1.024556            dave\n",
       "157229      1  0.834582           elton\n",
       "161907      1  0.903870            erin\n",
       "213136      1  0.902763           going\n",
       "216785      1  0.948708            good\n",
       "226500      1  0.719684             guy\n",
       "233591      1  0.892514           harry\n",
       "269274      1  0.839405        jennifer\n",
       "272031      1  0.715883           judge\n",
       "277443      1  0.868276           kelly\n",
       "282937      1  1.043697            know\n",
       "289907      1  0.696234            last\n",
       "291938      1  0.824571           laugh\n",
       "292810      1  0.886830        laughter\n",
       "301361      1  1.059290            like\n",
       "313336      1  0.916168            look\n",
       "318231      1  0.992431            love\n",
       "...       ...       ...             ...\n",
       "361678      1  0.687227    neighborhood\n",
       "366861      1  0.977767           night\n",
       "375655      1  0.895456            okay\n",
       "389616      1  0.691866         patient\n",
       "391590      1  1.091441          people\n",
       "396637      1  1.603090            phil\n",
       "424500      1  0.830078     queen kelly\n",
       "432890      1  0.988242          really\n",
       "442193      1  0.773911        reporter\n",
       "448498      1  0.873105           right\n",
       "460649      1  1.082342            said\n",
       "464940      1  0.837895             say\n",
       "484901      1  1.531843          shower\n",
       "494287      1  0.856350          smoker\n",
       "507702      1  1.024972            star\n",
       "512940      1  1.021191           steve\n",
       "530813      1  1.159651            take\n",
       "533415      1  0.871828            talk\n",
       "543274      1  1.128662           thank\n",
       "547507      1  1.105944           think\n",
       "555469      1  0.922062            time\n",
       "570368      1  0.836881          trauma\n",
       "571788      1  1.536100           trick\n",
       "592346      1  0.870504            want\n",
       "599906      1  1.034169            week\n",
       "602311      1  0.849372            well\n",
       "621354      1  0.924723            yeah\n",
       "623530      1  1.121813            year\n",
       "626942      1  1.000683            york\n",
       "626973      1  1.055592       york city\n",
       "\n",
       "[65 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[4, 1, 2, 5, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "pyLDAvis.sklearn.prepare(lda_tfidf, tfidf_model, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparcity:  100.0 %\n",
      "Log Likelihood:  -502107.54887255287\n",
      "Perplexity:  4067339.2058298644\n"
     ]
    }
   ],
   "source": [
    "print(\"Sparcity: \", ((tfidf_model > 0).sum()/tfidf_model.size)*100, \"%\")\n",
    "print(\"Log Likelihood: \", lda_tfidf.score(tfidf_model))\n",
    "print(\"Perplexity: \", lda_tfidf.perplexity(tfidf_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perplexity may not be the best measure to evaluate topic models because there is no consideration of the context and semantic associations between words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params = {'n_components': [3, 5, 8, 10], 'learning_decay': [.5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
       "             evaluate_every=-1, learning_decay=0.7, learning_method=None,\n",
       "             learning_offset=10.0, max_doc_update_iter=100, max_iter=10,\n",
       "             mean_change_tol=0.001, n_components=10, n_jobs=1,\n",
       "             n_topics=None, perp_tol=0.1, random_state=None,\n",
       "             topic_word_prior=None, total_samples=1000000.0, verbose=0),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'n_components': [3, 5, 8, 10], 'learning_decay': [0.5]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation()\n",
    "model = GridSearchCV(lda, param_grid=search_params)\n",
    "model.fit(tfidf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model's Params:  {'learning_decay': 0.5, 'n_components': 3}\n",
      "Best Log Likelihood Score:  -169063.6091528614\n",
      "Model Perplexity:  1808413.757669866\n"
     ]
    }
   ],
   "source": [
    "best_lda_model = model.best_estimator_\n",
    "\n",
    "print(\"Best Model's Params: \", model.best_params_)\n",
    "print(\"Best Log Likelihood Score: \", model.best_score_)\n",
    "print(\"Model Perplexity: \", best_lda_model.perplexity(tfidf_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-667acc2e9b4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlda_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_lda_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtfidf_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtopicnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Topic\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_lda_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_topics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdocnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Doc\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "lda_output = best_lda_model.transform(tfidf_model)\n",
    "topicnames = [\"Topic\" + str(i) for i in range(best_lda_model.n_topics)]\n",
    "docnames = [\"Doc\" + str(i) for i in range(len(text))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_document_topic = pd.DataFrame(np.round(lda_output, 2), columns=topicnames, index=docnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NoneType"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file(\"toolbar.html\")\n",
    "\n",
    "source = ColumnDataSource(data=dict(\n",
    "    x=[1, 2, 3, 4, 5],\n",
    "    y=[2, 5, 8, 2, 7],\n",
    "    desc=['A', 'b', 'C', 'd', 'E'],\n",
    "))\n",
    "\n",
    "TOOLTIPS = [\n",
    "    (\"index\", \"$index\"),\n",
    "    (\"(x,y)\", \"($x, $y)\"),\n",
    "    (\"desc\", \"@desc\"),\n",
    "]\n",
    "\n",
    "p = figure(plot_width=400, plot_height=400, tooltips=TOOLTIPS,\n",
    "           title=\"Mouse over the dots\")\n",
    "\n",
    "p.circle('x', 'y', size=20, source=source)\n",
    "\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
